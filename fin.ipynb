{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import urllib3\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json파일 불러옴 (85개 파일)\n",
    "len_rawdata=0\n",
    "raw_data={\"utterance\":[]}\n",
    "\n",
    "for k in range(0,100):\n",
    "    if k <100:\n",
    "        name=\"DKSR200000\"+str(k)+\".json\"\n",
    "    elif 100<= k and k<1000:\n",
    "        name=\"DKSR20000\"+str(k)+\".json\"\n",
    "    try:\n",
    "        f = open(\"[라벨]경상도_학습데이터_1/\"+name, encoding=\"UTF-8\")\n",
    "        data = json.loads(f.read())\n",
    "        raw_data[\"utterance\"].extend(data[\"utterance\"])\n",
    "        #print(data[\"speaker\"][1][\"age\"],data[\"speaker\"][1][\"birthplace\"],data[\"speaker\"][1][\"principal_residence\"])\n",
    "        len_rawdata += 1\n",
    "\n",
    "    except:\n",
    "        #print(\"실패\")\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사투리, 표준어 사전 생성 함수\n",
    "def make_dict(raw_data):\n",
    "\n",
    "    dialect_word = []\n",
    "    standard_word = [] \n",
    "    all_std_word=[]\n",
    "\n",
    "    filter = re.compile('[^가-힣+]')    \n",
    "    \n",
    "    for i in range(len(raw_data[\"utterance\"])):\n",
    "        #print(raw_data[\"utterance\"])\n",
    "        eojeol = raw_data[\"utterance\"][i][\"eojeolList\"]\n",
    "            \n",
    "        for k in range(len(eojeol)):\n",
    "            if eojeol[k][\"isDialect\"] == True:\n",
    "                # print(eojeol[k][\"eojeol\"])\n",
    "                # print(dialect_word)\n",
    "                if filter.sub('', eojeol[k]['eojeol']) not in dialect_word :\n",
    "                    dlt = filter.sub('', eojeol[k]['eojeol'])\n",
    "                    std = filter.sub('', eojeol[k]['standard'])\n",
    "                    if dlt==\"\" or std==\"\":\n",
    "                        #print(\"dd\", eojeol[k]['eojeol'], \"dd\")\n",
    "                        pass\n",
    "                    else:\n",
    "                        dialect_word.append(dlt)\n",
    "                        standard_word.append(std)\n",
    "            else:\n",
    "                if eojeol[k][\"standard\"] not in standard_word:\n",
    "                    word = filter.sub('', eojeol[k]['standard'])\n",
    "                    if word == \"\":\n",
    "                        pass\n",
    "                        #print(\"dd\", eojeol[k]['eojeol'], \"dd\")\n",
    "                    else:\n",
    "                        all_std_word.append(word)\n",
    "\n",
    "    word_dictionary = pd.DataFrame([dialect_word, standard_word])\n",
    "    word_dictionary = word_dictionary.transpose()\n",
    "    word_dictionary.columns = ['dialect', 'standard']\n",
    "    dialect_dictionary = word_dictionary['dialect']\n",
    "    standard_dictionary = word_dictionary['standard']\n",
    "\n",
    "    index_to_dialect = dialect_dictionary.to_dict()\n",
    "    index_to_standard = standard_dictionary.to_dict() #{인덱스:\"단어\"}\n",
    "\n",
    "    dialect_to_index = {v:k for k,v in index_to_dialect.items()}\n",
    "    standard_to_index = {v:k for k,v in index_to_standard.items()}#{\"단어\":인덱스}\n",
    "    \n",
    "    return dialect_to_index,standard_to_index,index_to_dialect,index_to_standard,all_std_word   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "349\n",
      "389\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "dialect_to_index,standard_to_index,index_to_dialect,index_to_standard,all_std_word = make_dict(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사투리 표준어 쌍 생성 함수\n",
    "def make_pair(raw_data):\n",
    "    filter = re.compile('[^가-힣+]')\n",
    "\n",
    "    dialect_form = []\n",
    "    standard_form = []\n",
    "\n",
    "    for i in range(len(raw_data[\"utterance\"])):\n",
    "        sentence = raw_data[\"utterance\"][i]\n",
    "        \n",
    "        for j in range(len(sentence[\"eojeolList\"])):\n",
    "            #print(sentence[\"eojeolList\"][0]['eojeol'])\n",
    "            if sentence[\"eojeolList\"][j]['isDialect'] == True:\n",
    "                try : \n",
    "                    dialect = sentence[\"eojeolList\"][j][\"eojeol\"]\n",
    "                    standard = sentence[\"eojeolList\"][j][\"standard\"]\n",
    "                    \n",
    "                    dialect = filter.sub('', dialect)\n",
    "                    standard = filter.sub('', standard)\n",
    "                    \n",
    "                    dialect_idx = dialect_to_index[dialect]\n",
    "                    #standard_idx = standard_to_index[standard]\n",
    "                    standard_idx = [k for k, v in index_to_standard.items() if v == standard][0]\n",
    "\n",
    "                    dialect_form.append(dialect_idx)\n",
    "                    standard_form.append(standard_idx)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    result = pd.DataFrame(data = {\"dialect_words\":dialect_form, \"standard_words\": standard_form})\n",
    "\n",
    "    return result               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialect_words</th>\n",
       "      <th>standard_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialect_words  standard_words\n",
       "0              0               0\n",
       "1              1               1\n",
       "2              2               0\n",
       "3              0               0\n",
       "4              3               3\n",
       "5              1               1\n",
       "6              0               0\n",
       "7              0               0\n",
       "8              4               4\n",
       "9              0               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = make_pair(raw_data)\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사투리 사전에 존재하는지 확인하는 함수\n",
    "def exist_in_dialect(x):\n",
    "\n",
    "    if x in dialect_to_index:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_xtrain = np_utils.to_categorical(pairs[\"dialect_words\"])\n",
    "trans_ytrain = np_utils.to_categorical(pairs[\"standard_words\"])\n",
    "len(trans_xtrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_model = Sequential()\n",
    "translate_model.add(Dense(256, input_dim = 389, activation=\"relu\"))\n",
    "translate_model.add(Dense(389, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 3ms/step - loss: 5.9201 - accuracy: 0.2145\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.7463 - accuracy: 0.5776\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.5435 - accuracy: 0.5835\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.2657 - accuracy: 0.5701\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.8784 - accuracy: 0.5384\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 4.3624 - accuracy: 0.5217\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7244 - accuracy: 0.4900\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0981 - accuracy: 0.4841\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6072 - accuracy: 0.5008\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2915 - accuracy: 0.5609\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0737 - accuracy: 0.6035\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8997 - accuracy: 0.6402\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7495 - accuracy: 0.6611\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6165 - accuracy: 0.6753\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.4945 - accuracy: 0.6962\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3816 - accuracy: 0.7287\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2753 - accuracy: 0.7546\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.1757 - accuracy: 0.7613\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0789 - accuracy: 0.7679\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.7855\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.8962 - accuracy: 0.8456\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.8125 - accuracy: 0.9098\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7299 - accuracy: 0.9766\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.9933\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.9983\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.9983\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.9983\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.9983\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9983\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9983\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9983\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9983\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9983\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9983\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9983\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9983\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9983\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9983\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9983\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9983\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9975\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9975\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9983\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9975\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22adb61cc18>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_model.fit(trans_xtrain, trans_ytrain, batch_size=100, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사투리 단어 번역 함수\n",
    "def translate(word):\n",
    "    index = dialect_to_index[word]\n",
    "    one_hot = np_utils.to_categorical(index,len(trans_xtrain[0])) #인덱스 배열의크기 지정 필요 size_of_dialect\n",
    "    #print(translate_model.predict(np.array([one_hot])))\n",
    "    pred_index = np.argmax(translate_model.predict(np.array([one_hot])))\n",
    "    print(pred_index)\n",
    "    #print(len(translate_model.predict(np.array([one_hot]))[0]))\n",
    "    res = index_to_standard[pred_index]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이제'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"인자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사 사전\n",
    "a_tag = ['NP','VP','AP','VNP','DP','IP','X','L','R']\n",
    "b_tag = ['SBJ','OBJ','MOD','AJT','CMP','CNJ']\n",
    "c_tag = []\n",
    "pos_dict = {}\n",
    "for i in a_tag:\n",
    "    for j in b_tag:\n",
    "        c_tag.append(i+\"_\"+j)\n",
    "c_tag.extend(a_tag)\n",
    "c_tag.extend(b_tag)\n",
    "for i in range(len(c_tag)):\n",
    "    pos_dict[c_tag[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 전체 어절을 딕셔너리로 만듦\n",
    "def make_eojeol(index_to_standard, dialect_to_index, all_std_word):\n",
    "\n",
    "    eojeol_list=[]\n",
    "    st_list = []\n",
    "    di_list = []\n",
    "    \n",
    "    for k in index_to_standard.values():\n",
    "        st_list.append(k)\n",
    "    print(len(st_list))\n",
    " \n",
    "\n",
    "    for v in dialect_to_index:\n",
    "        di_list.append(v)\n",
    "    print(len(di_list))    \n",
    "\n",
    "    for i, j in zip(st_list, di_list):\n",
    "        eojeol_list.append(i)\n",
    "        eojeol_list.append(j + \"0\")\n",
    "        \n",
    "    for i in all_std_word:\n",
    "        eojeol_list.append(i) \n",
    "\n",
    "    eojeol_df = pd.DataFrame(eojeol_list, columns=None)\n",
    "    eojeol_dict = eojeol_df.to_dict()\n",
    "    eojeol_dict = eojeol_dict[0]\n",
    "    eojeol_dict = {v:k for k,v in eojeol_dict.items()}\n",
    "\n",
    "    #print(eojeol_dict)\n",
    "\n",
    "    return eojeol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n",
      "389\n"
     ]
    }
   ],
   "source": [
    "eojeol_dict = make_eojeol(index_to_standard, dialect_to_index, all_std_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31682"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eojeol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동의어 사전 만드는 함수\n",
    "def make_synonym_list(eojeol_dict):\n",
    "    synonym_list=[]\n",
    "    for i in eojeol_dict.keys():\n",
    "        if i[-1]==\"0\":\n",
    "            for j in eojeol_dict.keys():\n",
    "                tmp=i[:-1]\n",
    "                if tmp==j:\n",
    "                    synonym_list.append(tmp)\n",
    "                    #print(i,j)\n",
    "        else:\n",
    "            pass\n",
    "    return synonym_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_list = make_synonym_list(eojeol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그래', '그니까', '땜에', '있나', '먹었다', '아이가', '내', '될려면', '따른', '그러고']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 연관된 단어의 품사를 API를 사용해서 가져오기\n",
    "def get_mods_pos(std_str, dlt_str):\n",
    "    \n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "    accessKey = \"aba3a45d-3318-4061-8a5d-799c8521b082\"\n",
    "    analysisCode = \"dparse\"\n",
    "\n",
    "    text = std_str\n",
    "    \n",
    "    requestJson = {\n",
    "        \"access_key\": accessKey,\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": analysisCode\n",
    "        }\n",
    "    }\n",
    "          \n",
    "    http = urllib3.PoolManager()\n",
    "\n",
    "    response = http.request(\n",
    "        \"POST\",\n",
    "        openApiURL,\n",
    "        headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "        body=json.dumps(requestJson)\n",
    "    )\n",
    "\n",
    "    tmp = ast.literal_eval(response.data.decode('utf-8'))\n",
    "\n",
    "    words = []\n",
    "    poses = []\n",
    "    \n",
    "    #try : \n",
    "    if tmp[\"result\"] == -1:\n",
    "\n",
    "        print(tmp)\n",
    "\n",
    "    std_list = std_str.split(\". \")\n",
    "    dlt_list = dlt_str.split(\". \")\n",
    "    key = True\n",
    "    ket = False\n",
    "    for t in range(len(std_list)-1):\n",
    "        tmp[\"return_object\"][\"sentence\"][t]\n",
    "\n",
    "        std = std_list[t].split()\n",
    "        dlt = dlt_list[t].split()\n",
    "\n",
    "        try : \n",
    "            for i in range(len(tmp[\"return_object\"][\"sentence\"][t][\"dependency\"])):\n",
    "                dict_with_mods = tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][i][\"mod\"]\n",
    "                # print(\"-------\")\n",
    "                # print(tmp[\"return_object\"][\"sentence\"][t][\"dependency\"])\n",
    "                #print(\"현재단어\",tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][i][\"text\"])\n",
    "                \n",
    "                for m in dict_with_mods:\n",
    "                    #print(\"모드있음\")\n",
    "                    #print(i)\n",
    "                    if tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][i][\"text\"] != \".\":\n",
    "                        if std[i] != dlt[i]:\n",
    "                            #print(\"사투리임\")\n",
    "                            # print(words)\n",
    "                            \n",
    "                            if dlt[i]+\"0\" in eojeol_dict.keys():\n",
    "                                #print(\"동의어 사투리라서 두개 다 넣음\", dlt[i], std[i])                            \n",
    "                        \n",
    "                                words.append(eojeol_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][int(m)][\"text\"]])\n",
    "                                key=True\n",
    "                                poses.append(pos_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][i][\"label\"]])\n",
    "                                key=False\n",
    "\n",
    "                                words.append(eojeol_dict[dlt[i]+\"0\"])\n",
    "                                key=True\n",
    "                                poses.append(pos_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][int(m)][\"label\"]])\n",
    "                                key=False\n",
    "\n",
    "                                words.append(eojeol_dict[std[i]])\n",
    "                                key=True\n",
    "                                poses.append(pos_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][int(m)][\"label\"]])\n",
    "                                key=False\n",
    "                            # else:\n",
    "                            #     # print(\"사투리 사전에 없음\")\n",
    "\n",
    "                        else:\n",
    "                            #print(\"사투리아님\")\n",
    "                            if std[i]+\"0\" in eojeol_dict.keys():\n",
    "                                \n",
    "                                words.append(eojeol_dict[std[i]])\n",
    "                                key=True\n",
    "                                poses.append(pos_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][int(m)][\"label\"]])\n",
    "                                key=False\n",
    "\n",
    "                                words.append(eojeol_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][int(m)][\"text\"]])\n",
    "                                key=True\n",
    "                                poses.append(pos_dict[tmp[\"return_object\"][\"sentence\"][t][\"dependency\"][i][\"label\"]])\n",
    "                                key=False\n",
    "            \n",
    "            #print(\"성공\")\n",
    "\n",
    "        except:\n",
    "            #print(\"실패\")\n",
    "            if key == True:\n",
    "                words.pop()\n",
    "            #print(len(words), len(poses))\n",
    "\n",
    "    # except:\n",
    "    #     print(tmp)\n",
    "\n",
    "    #print(words, poses)\n",
    "    return words, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_data[\"utterance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 인덱스와 연결된 단어의 품사 인덱스 \n",
    "\n",
    "def eojeol_dependence(raw_data, synonym_list):\n",
    "    words=[]\n",
    "    poses=[]\n",
    "    std_str=\"\"\n",
    "    dlt_str=\"\"\n",
    "    count = 0\n",
    "    num=0\n",
    "    for i in raw_data[\"utterance\"]:\n",
    "\n",
    "        # 문장\n",
    "        std = i[\"standard_form\"]\n",
    "        dlt = i[\"dialect_form\"]\n",
    "        \n",
    "        filter = re.compile('[^가-힣 +]')\n",
    "\n",
    "        # 불용어 제거 문장\n",
    "        dlt = filter.sub('', dlt)\n",
    "        std = filter.sub('', std)\n",
    "\n",
    "        # 문장 이어붙임\n",
    "        total = dlt.split() + std.split()\n",
    "\n",
    "        # 이어붙인 문장의 어절을 돌면서\n",
    "        for eojeol in total:\n",
    "            if eojeol in synonym_list: # 동의어 목록에 있는 어절을 발견하면\n",
    "                # get_mods_pos로 넘길 str에 추가\n",
    "                dlt_str = dlt_str + dlt + \". \"\n",
    "                std_str = std_str + std + \". \"\n",
    "                count = count + 1\n",
    "                break\n",
    "\n",
    "        if count >= 200: #문장 총 개수 22500개, 동의어가 있는 문장이 200개가 넘으면 API 사용 -> API 사용횟수 : 약 100회   \n",
    "            #print(num) \n",
    "            num +=1\n",
    "            word, pos = get_mods_pos(std_str, dlt_str)\n",
    "            words.extend(word)\n",
    "            poses.extend(pos)\n",
    "            count = 0\n",
    "            std_str = \"\"\n",
    "            dlt_str = \"\"\n",
    "\n",
    "    df = pd.DataFrame(data = {\"pos\":poses, \"word\":words })\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>57</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>58</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>3</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>0</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word\n",
       "923    54  148241\n",
       "1868   54  148241\n",
       "1870   57  148241\n",
       "1872    8  148241\n",
       "1874   54  148241\n",
       "1878    8  148241\n",
       "2067   54  148241\n",
       "4785   58  148241\n",
       "5176    8  148241\n",
       "5700   54  148241\n",
       "5706   54  148241\n",
       "6019    3  148241\n",
       "6021    0  148241\n",
       "6023   54  148241"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"] == 148241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148241"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"아이가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = eojeol_dependence(raw_data, synonym_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>155171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>149387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>116685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>149387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>55</td>\n",
       "      <td>156279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>3</td>\n",
       "      <td>155743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>8</td>\n",
       "      <td>156026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>55</td>\n",
       "      <td>156016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>57</td>\n",
       "      <td>145693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6133 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word\n",
       "0      55  155171\n",
       "1      55     953\n",
       "2      55  149387\n",
       "3      54  116685\n",
       "4      56  149387\n",
       "...   ...     ...\n",
       "6128   55  156279\n",
       "6129    3  155743\n",
       "6130    8  156026\n",
       "6131   55  156016\n",
       "6132   57  145693\n",
       "\n",
       "[6133 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"pos\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "train_df = train_df[[\"pos\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df[\"word\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩을 하기 위해 \n",
    "index_word={} # \n",
    "num=0\n",
    "for i in train_df[\"word\"]:\n",
    "    if i not in index_word.keys():\n",
    "        index_word[i] = num\n",
    "        num += 1\n",
    "#print(index_word)\n",
    "word_index_col=[]\n",
    "for i in train_df[\"word\"]:\n",
    "    word_index_col.append(index_word[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>155171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>116685</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>55</td>\n",
       "      <td>156279</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>3</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>8</td>\n",
       "      <td>156026</td>\n",
       "      <td>1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>55</td>\n",
       "      <td>156016</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>57</td>\n",
       "      <td>145693</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6133 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word  word_index_col\n",
       "0      55  155171               0\n",
       "1      55     953               1\n",
       "2      55  149387               2\n",
       "3      54  116685               3\n",
       "4      56  149387               2\n",
       "...   ...     ...             ...\n",
       "6128   55  156279              52\n",
       "6129    3  155743               8\n",
       "6130    8  156026            1572\n",
       "6131   55  156016              25\n",
       "6132   57  145693             264\n",
       "\n",
       "[6133 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"word_index_col\"] = word_index_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>155171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>116685</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54</td>\n",
       "      <td>141550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>104230</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>144143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>151458</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>141550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>155917</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>2194</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>103900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59</td>\n",
       "      <td>155917</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54</td>\n",
       "      <td>156050</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>155917</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54</td>\n",
       "      <td>155495</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>2235</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>2236</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>56</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>100389</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>152721</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55</td>\n",
       "      <td>141607</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pos    word  word_index_col\n",
       "0    55  155171               0\n",
       "1    55     953               1\n",
       "2    55  149387               2\n",
       "3    54  116685               3\n",
       "4    56  149387               2\n",
       "5    54  141550               4\n",
       "6    56  149387               2\n",
       "7    54  104230               5\n",
       "8    59  144143               6\n",
       "9    57  151458               7\n",
       "10   56  155743               8\n",
       "11    8  141550               4\n",
       "12   56  155743               8\n",
       "13    8  155917               9\n",
       "14    3  155743               8\n",
       "15    8    2194              10\n",
       "16   55  155743               8\n",
       "17    8  103900              11\n",
       "18   59  155917               9\n",
       "19   54  156050              12\n",
       "20   56  155917               9\n",
       "21   54  155495              13\n",
       "22   55  155743               8\n",
       "23    8    2235              14\n",
       "24    0  155743               8\n",
       "25    8    2236              15\n",
       "26   56  155743               8\n",
       "27    8  100389              16\n",
       "28    3  152721              17\n",
       "29   55  141607              18"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 인덱스와 연결된 단어의 품사 인덱스\n",
    "#def eojeol_dependence_():\n",
    "\n",
    "    # 언어 분석 기술(문어)\n",
    "    # openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    # accessKey = \"aba3a45d-3318-4061-8a5d-799c8521b082\"\n",
    "    # analysisCode = \"dparse\"\n",
    "\n",
    "    # text = \"엑소브레인은 내 몸 바깥에 있는 인공 두뇌라는 뜻으로, 세계 최고인공지능 기술 선도라는 비전을 달성하기 위한 과학기술정보통신부 소프트웨어 분야의 국가 혁신기술 개발형 연구개발 과제이다.\"\n",
    "    # requestJson = {\n",
    "    #     \"access_key\": accessKey,\n",
    "    #     \"argument\": {\n",
    "    #         \"text\": text,\n",
    "    #         \"analysis_code\": analysisCode\n",
    "    #     }\n",
    "    # }\n",
    "    # http = urllib3.PoolManager()\n",
    "    # response = http.request(\n",
    "    #     \"POST\",\n",
    "    #     openApiURL,\n",
    "    #     headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "    #     body=json.dumps(requestJson)\n",
    "    # )\n",
    "\n",
    "    # s=ast.literal_eval(response.data.decode('utf-8'))\n",
    "\n",
    "    # dep=s['return_object']['sentence'][0]['dependency']\n",
    "    \n",
    "    # eojeol_d=[]\n",
    "    # pos_d=[]\n",
    "\n",
    "    # re_eojeol_dict = {v:k for k,v in eojeol_dict.items()} #{인덱스:문자}\n",
    "        \n",
    "    # for i in range(len(dep)): #dep(딕셔너리)길이만큼 반복 23\n",
    "    #     if dep[i]['text'] in eojeol_dict:\n",
    "    #         eojeol_d.append(eojeol_dict.values())\n",
    "    #     for j in range(len(dep[i]['mod'])):\n",
    "    #         mod=dep[i]['mod']\n",
    "    #         print(mod[j])\n",
    "    #         if len(mod[j]) > 0:\n",
    "    #             pos=re_eojeol_dict.get(mod[j])#결과값:문자\n",
    "    #             #mod가 가리키는 어절의 품사를 확인하는 방법..\n",
    "    #             if dep[i]['label'] in pos_dict:\n",
    "    #                 pos_d.append(pos_dict.values())\n",
    "    #             else:\n",
    "    #                 return None\n",
    "                \n",
    "    # result = pd.DataFrame(data = {\"word_dic\":eojeol_d, \"mod_dic\":pos_d})\n",
    "    # return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_xtrain = np_utils.to_categorical(train_df[\"pos\"])\n",
    "synonym_ytrain = np_utils.to_categorical(train_df[\"word_index_col\"])\n",
    "len(synonym_ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6133, 60)\n",
      "(6133, 1573)\n"
     ]
    }
   ],
   "source": [
    "print(synonym_xtrain.shape)\n",
    "print(synonym_ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_model = Sequential()\n",
    "synonym_model.add(Dense(512, input_dim = 60, activation=\"relu\"))\n",
    "synonym_model.add(Dense(256,activation=\"relu\"))\n",
    "synonym_model.add(Dense(128,activation=\"relu\"))\n",
    "synonym_model.add(Dense(1573, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 1s 26ms/step - loss: 7.2769 - accuracy: 0.1159\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 6.3156 - accuracy: 0.1500\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 5.5938 - accuracy: 0.1314\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 5.4219 - accuracy: 0.1660\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 5.2840 - accuracy: 0.1798\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 5.1802 - accuracy: 0.1794\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 5.0957 - accuracy: 0.1875\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 5.0202 - accuracy: 0.1935\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.9528 - accuracy: 0.1931\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 4.8964 - accuracy: 0.1944\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 4.8466 - accuracy: 0.1939\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 4.8057 - accuracy: 0.1935\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.7746 - accuracy: 0.1942\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 4.7470 - accuracy: 0.1937\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.7278 - accuracy: 0.1940\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 4.7141 - accuracy: 0.1945\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 4.7001 - accuracy: 0.1960\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 4.6865 - accuracy: 0.1953\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 4.6737 - accuracy: 0.1948\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 4.6641 - accuracy: 0.1953\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 4.6543 - accuracy: 0.1944\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 4.6511 - accuracy: 0.1944\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 4.6400 - accuracy: 0.1957\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 4.6358 - accuracy: 0.1958\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.6286 - accuracy: 0.1945\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.6250 - accuracy: 0.1955\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.6214 - accuracy: 0.1958\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.6142 - accuracy: 0.1948\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 4.6119 - accuracy: 0.1958\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 4.6114 - accuracy: 0.1931\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 4.6075 - accuracy: 0.1958\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 4.6054 - accuracy: 0.1880\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.6023 - accuracy: 0.1939\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.5986 - accuracy: 0.1957\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.5935 - accuracy: 0.1948\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5934 - accuracy: 0.1962\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.5913 - accuracy: 0.1962\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 4.5893 - accuracy: 0.1960\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 4.5896 - accuracy: 0.1940\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5859 - accuracy: 0.1957\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 4.5849 - accuracy: 0.1952\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5819 - accuracy: 0.1962\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5806 - accuracy: 0.1957\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 4.5805 - accuracy: 0.1960\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5807 - accuracy: 0.1950\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5800 - accuracy: 0.1940\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 4.5788 - accuracy: 0.1957\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 4.5791 - accuracy: 0.1965\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5754 - accuracy: 0.1965\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 4.5753 - accuracy: 0.1958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2ac5b63c8>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_model.fit(synonym_xtrain, synonym_ytrain, batch_size=500, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148241"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"아이가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"아이가0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_model.save(\"synonym_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "synonym_model = load_model(\"synonym_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               31232     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1573)              202917    \n",
      "=================================================================\n",
      "Total params: 398,373\n",
      "Trainable params: 398,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "synonym_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 연관된 단어의 품사 추출\n",
    "def get_mods(sentence, num):\n",
    "    #print(sentence, num)\n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "    accessKey = \"aba3a45d-3318-4061-8a5d-799c8521b082\"\n",
    "    \n",
    "    #bd6d2bff-4e44-4035-8591-947fda262051\n",
    "    analysisCode = \"dparse\"\n",
    "\n",
    "    text = sentence\n",
    "    \n",
    "    requestJson = {\n",
    "        \"access_key\": accessKey,\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": analysisCode\n",
    "        }\n",
    "    }\n",
    "\n",
    "    http = urllib3.PoolManager()\n",
    "\n",
    "    response = http.request(\n",
    "        \"POST\",\n",
    "        openApiURL,\n",
    "        headers={\"Content-Type\": \"application/json; charset=UTF-8\"},\n",
    "        body=json.dumps(requestJson)\n",
    "    )\n",
    "\n",
    "    tmp = ast.literal_eval(response.data.decode('utf-8'))\n",
    "    #print(tmp)\n",
    "    dict_with_mods = tmp[\"return_object\"][\"sentence\"][0][\"dependency\"]\n",
    "    id_dict={}\n",
    "    print(dict_with_mods)\n",
    "    for i in dict_with_mods[num][\"mod\"]:\n",
    "        id_dict[dict_with_mods[int(i)][\"weight\"]] = int(i)\n",
    "        #print(i)\n",
    "    id = id_dict[max(id_dict)]\n",
    "    \n",
    "    pos = dict_with_mods[id][\"label\"]\n",
    "\n",
    "    \n",
    "    return pos, dict_with_mods[id][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동의어 처리를 포함한 사투리 번역 함수\n",
    "def predict_standard(sentence):\n",
    "    global index_to_standard\n",
    "    res = \"\"\n",
    "    mark = \"\"\n",
    "    if sentence[-1] in [\".\", \"?\", \"!\"]:\n",
    "        mark = sentence[-1]\n",
    "        sentence = sentence[:-1]\n",
    "\n",
    "    sentence_sep = sentence.split()\n",
    "    \n",
    "        \n",
    "    #print(sentence_sep)\n",
    "    for i in range(len(sentence_sep)):\n",
    "        #print(sentence_sep[i])\n",
    "        if exist_in_dialect(sentence_sep[i]) == True: #사투리 사전에 있으면\n",
    "            if sentence_sep[i] in eojeol_dict.keys(): #해당 단어가 전체 사전에 있으면\n",
    "                #print(sentence_sep[i] )\n",
    "                pos, _ = get_mods(sentence, i) #연관된 단어의 품사 받아옴\n",
    "                pos_idx = pos_dict[pos] #품사의 인덱스\n",
    "                \n",
    "                word = sentence_sep[i]\n",
    "                print(i, word) \n",
    "                print(eojeol_dict[word+\"0\"])\n",
    "                print(eojeol_dict[word])\n",
    "                word0_idx = index_word[ eojeol_dict[word+\"0\"]] #단어0의 인덱스\n",
    "                word_idx = index_word[eojeol_dict[word]] #단어의 인덱스\n",
    "                #print(word0_idx)\n",
    "                # temp = result[word_idx]\n",
    "                # print(type(temp))\n",
    "\n",
    "                one_hot = np_utils.to_categorical(pos_idx,len(synonym_xtrain[0])) #인덱스 배열의크기 지정 필요 size_of_dialect\n",
    "                #print((one_hot))\n",
    "                \n",
    "                percentage = synonym_model.predict(np.array([one_hot])) # 동의어 처리 모델\n",
    "                #print(\"ㅇㅇ\",percentage[0])\n",
    "\n",
    "                \n",
    "                res_idx = max(percentage[0][word0_idx], percentage[0][word_idx]) # 둘 중 더 큰 확률값\n",
    "                print(\"사투리확률\", percentage[0][word0_idx])\n",
    "                print(\"표준어확률\", percentage[0][word_idx])\n",
    "                \n",
    "                if percentage[0][word0_idx] > percentage[0][word_idx]:\n",
    "\n",
    "                    word = translate(word)\n",
    "                else: \n",
    "                    pass\n",
    "\n",
    "                res = res + \" \" + word\n",
    "                #res = res + \" \" + index_to_standard[pred_index]\n",
    "            else: #해당 단어가 전체 사전에 없으면 -> 동의어가 없으므로 바로 번역 모델에 넣음\n",
    "                \n",
    "                word = sentence_sep[i]\n",
    "                res = res + \" \" + translate(word)\n",
    "        else:\n",
    "            word = sentence_sep[i]\n",
    "            #print(word,\"사투리가아님\")\n",
    "            res = res + \" \" + word\n",
    "    if mark != \"\":\n",
    "        res = res + mark\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>155171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>149387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>155743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>55</td>\n",
       "      <td>155495</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>55</td>\n",
       "      <td>151880</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>55</td>\n",
       "      <td>155902</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>55</td>\n",
       "      <td>156279</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>55</td>\n",
       "      <td>156016</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word  word_index_col\n",
       "0      55  155171               0\n",
       "1      55     953               1\n",
       "2      55  149387               2\n",
       "16     55  155743               8\n",
       "22     55  155743               8\n",
       "...   ...     ...             ...\n",
       "6120   55  155495              13\n",
       "6122   55  151880            1571\n",
       "6124   55  155902             219\n",
       "6128   55  156279              52\n",
       "6131   55  156016              25\n",
       "\n",
       "[2571 rows x 3 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"pos\"]==55] #pos \"VP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos  word  word_index_col\n",
       "274    55    37             113\n",
       "836     4    37             113\n",
       "856    55    37             113\n",
       "876    55    37             113\n",
       "931    55    37             113\n",
       "947    55    37             113\n",
       "972    55    37             113\n",
       "1219   55    37             113\n",
       "1237   55    37             113\n",
       "1257   55    37             113\n",
       "1301   55    37             113\n",
       "1339   55    37             113\n",
       "1392   55    37             113\n",
       "1412   55    37             113\n",
       "1431   55    37             113\n",
       "1440   55    37             113\n",
       "1446   55    37             113"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"]==37] # 사투리 \"아이가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>57</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>58</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>8</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>3</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>0</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>54</td>\n",
       "      <td>148241</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word  word_index_col\n",
       "923    54  148241             330\n",
       "1868   54  148241             330\n",
       "1870   57  148241             330\n",
       "1872    8  148241             330\n",
       "1874   54  148241             330\n",
       "1878    8  148241             330\n",
       "2067   54  148241             330\n",
       "4785   58  148241             330\n",
       "5176    8  148241             330\n",
       "5700   54  148241             330\n",
       "5706   54  148241             330\n",
       "6019    3  148241             330\n",
       "6021    0  148241             330\n",
       "6023   54  148241             330"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"]==148241] #표준어 \"아이가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'있지'"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"있다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148241"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"아이가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"있다0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>55</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>56</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>55</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos  word  word_index_col\n",
       "1330   55   171             458\n",
       "1333   56   171             458\n",
       "1336    0   171             458\n",
       "4951   55   171             458\n",
       "4954   59   171             458\n",
       "4957    1   171             458"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"]==171] #사투리 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>word_index_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>3</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>56</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>56</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>3</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>0</td>\n",
       "      <td>155786</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    word  word_index_col\n",
       "35      0  155786              23\n",
       "56      0  155786              23\n",
       "76      0  155786              23\n",
       "206     0  155786              23\n",
       "323     3  155786              23\n",
       "...   ...     ...             ...\n",
       "5955   56  155786              23\n",
       "5957   56  155786              23\n",
       "5959    3  155786              23\n",
       "6007    0  155786              23\n",
       "6083    0  155786              23\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"word\"]==155786] #표준어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 뭐라카노'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"뭐라카노\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '오늘', 'head': 2.0, 'label': 'NP', 'mod': [], 'weight': 0.0825357}, {'id': 1.0, 'text': '수업을', 'head': 2.0, 'label': 'NP_OBJ', 'mod': [], 'weight': 0.667639}, {'id': 2.0, 'text': '하나', 'head': -1.0, 'label': 'NP', 'mod': [0.0, 1.0], 'weight': 0.0266307}]\n",
      "2 하나\n",
      "203\n",
      "155170\n",
      "사투리확률 0.0033866374\n",
      "표준어확률 0.0009904605\n",
      "101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 오늘 수업을 하냐'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"오늘 수업을 하나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_standard(\"내가 얼른 글로 갈게\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '많이', 'head': 1.0, 'label': 'AP', 'mod': [], 'weight': 0.789286}, {'id': 1.0, 'text': '뭇다', 'head': 2.0, 'label': 'VP', 'mod': [0.0], 'weight': 0.15832}, {'id': 2.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [1.0], 'weight': 0.054921}]\n",
      "2 아이가\n",
      "37\n",
      "148241\n",
      "사투리확률 0.005546723\n",
      "표준어확률 1.0859945e-05\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 많이 뭇다 않아'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"많이 뭇다 아이가\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 맞지 이거 약간 모의 투자 느낌.'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"맞제 이거 약간 모의 투자 느낌.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 내가 집에서 손으로 다 해 먹거든예'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"내가 집에서 손으로 다 해 먹거든예\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '최고의', 'head': 1.0, 'label': 'NP_MOD', 'mod': [], 'weight': 0.58665}, {'id': 1.0, 'text': '리더는', 'head': 3.0, 'label': 'NP_SBJ', 'mod': [0.0], 'weight': 0.747763}, {'id': 2.0, 'text': '글을', 'head': 3.0, 'label': 'NP_OBJ', 'mod': [], 'weight': 0.732951}, {'id': 3.0, 'text': '쓴다', 'head': -1.0, 'label': 'VP', 'mod': [1.0, 2.0], 'weight': 0.23426}]\n",
      "3 쓴다\n",
      "89\n",
      "88112\n",
      "사투리확률 2.4423378e-05\n",
      "표준어확률 0.0022023644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 최고의 리더는 글을 쓴다.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"최고의 리더는 글을 쓴다.\") #표준어 쓴다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '최고의', 'head': 1.0, 'label': 'NP_MOD', 'mod': [], 'weight': 0.608439}, {'id': 1.0, 'text': '리더니까', 'head': 4.0, 'label': 'VNP', 'mod': [0.0], 'weight': 0.37775}, {'id': 2.0, 'text': '최고의', 'head': 3.0, 'label': 'NP_MOD', 'mod': [], 'weight': 0.56849}, {'id': 3.0, 'text': '글을', 'head': 4.0, 'label': 'NP_OBJ', 'mod': [2.0], 'weight': 0.688654}, {'id': 4.0, 'text': '쓴다', 'head': 5.0, 'label': 'VP', 'mod': [1.0, 3.0], 'weight': 0.336526}, {'id': 5.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [4.0], 'weight': 0.0141848}]\n",
      "4 쓴다\n",
      "89\n",
      "88112\n",
      "사투리확률 0.0025564772\n",
      "표준어확률 4.2879005e-06\n",
      "44\n",
      "[{'id': 0.0, 'text': '최고의', 'head': 1.0, 'label': 'NP_MOD', 'mod': [], 'weight': 0.608439}, {'id': 1.0, 'text': '리더니까', 'head': 4.0, 'label': 'VNP', 'mod': [0.0], 'weight': 0.37775}, {'id': 2.0, 'text': '최고의', 'head': 3.0, 'label': 'NP_MOD', 'mod': [], 'weight': 0.56849}, {'id': 3.0, 'text': '글을', 'head': 4.0, 'label': 'NP_OBJ', 'mod': [2.0], 'weight': 0.688654}, {'id': 4.0, 'text': '쓴다', 'head': 5.0, 'label': 'VP', 'mod': [1.0, 3.0], 'weight': 0.336526}, {'id': 5.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [4.0], 'weight': 0.0141848}]\n",
      "5 아이가\n",
      "37\n",
      "148241\n",
      "사투리확률 0.005546723\n",
      "표준어확률 1.0859945e-05\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 최고의 리더니까 최고의 글을 쓰지 않아?'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"최고의 리더니까 최고의 글을 쓴다 아이가?\") #사투리 쓴다, 사투리 아이가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '게임을', 'head': 3.0, 'label': 'NP_OBJ', 'mod': [], 'weight': 0.736509}, {'id': 1.0, 'text': '그렇게', 'head': 3.0, 'label': 'VP_AJT', 'mod': [], 'weight': 0.575393}, {'id': 2.0, 'text': '대충', 'head': 3.0, 'label': 'AP', 'mod': [], 'weight': 0.579023}, {'id': 3.0, 'text': '해가지고', 'head': 4.0, 'label': 'VP', 'mod': [0.0, 1.0, 2.0], 'weight': 0.532814}, {'id': 4.0, 'text': '이기겠나', 'head': -1.0, 'label': 'VP', 'mod': [3.0], 'weight': 0.10447}]\n",
      "3 해가지고\n",
      "643\n",
      "156118\n",
      "사투리확률 0.003530945\n",
      "표준어확률 0.1711169\n",
      "95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 게임을 그렇게 대충 해가지고 이길까?'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"게임을 그렇게 대충 해가지고 이기겠나?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '게임을', 'head': 3.0, 'label': 'NP_OBJ', 'mod': [], 'weight': 0.736048}, {'id': 1.0, 'text': '그렇게', 'head': 3.0, 'label': 'VP_AJT', 'mod': [], 'weight': 0.580144}, {'id': 2.0, 'text': '대충', 'head': 3.0, 'label': 'AP', 'mod': [], 'weight': 0.578524}, {'id': 3.0, 'text': '해가지고', 'head': 4.0, 'label': 'VP', 'mod': [0.0, 1.0, 2.0], 'weight': 0.516002}, {'id': 4.0, 'text': '이기긌나', 'head': -1.0, 'label': 'VP', 'mod': [3.0], 'weight': 0.100202}]\n",
      "3 해가지고\n",
      "643\n",
      "156118\n",
      "사투리확률 0.003530945\n",
      "표준어확률 0.1711169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 게임을 그렇게 대충 해가지고 이기긌나?'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"게임을 그렇게 대충 해가지고 이기긌나?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_to_index[\"아이가\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'않니'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_standard[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147024"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eojeol_dict[\"갖고\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word[154389]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialect_words</th>\n",
       "      <th>standard_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dialect_words  standard_words\n",
       "37              18              18\n",
       "137             18              41\n",
       "141             18              41\n",
       "145             18              41\n",
       "147             18              41\n",
       "150             18              41\n",
       "177             18              41\n",
       "182             18              41\n",
       "185             18              41\n",
       "197             18              41\n",
       "205             18              41\n",
       "217             18              41\n",
       "223             18              41\n",
       "229             18              41\n",
       "231             18              41\n",
       "233             18              41"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[pairs[\"dialect_words\"] == 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '어릴때', 'head': 4.0, 'label': 'VP', 'mod': [], 'weight': 0.238896}, {'id': 1.0, 'text': '옆집', 'head': 2.0, 'label': 'NP_SBJ', 'mod': [], 'weight': 0.0295369}, {'id': 2.0, 'text': '살던', 'head': 3.0, 'label': 'VP_MOD', 'mod': [1.0], 'weight': 0.42003}, {'id': 3.0, 'text': '가는', 'head': 4.0, 'label': 'VP_MOD', 'mod': [2.0], 'weight': 0.572229}, {'id': 4.0, 'text': '뭐하노', 'head': -1.0, 'label': 'VNP', 'mod': [0.0, 3.0], 'weight': 0.00104964}]\n",
      "3 가는\n",
      "281\n",
      "155743\n",
      "사투리확률 0.002120091\n",
      "표준어확률 0.004655487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 어릴때 옆집 살던 가는 뭐하노?'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_synonym(\"어릴때 옆집 살던 가는 뭐하노?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '착한', 'head': 1.0, 'label': 'VP_MOD', 'mod': [], 'weight': 0.625791}, {'id': 1.0, 'text': '아이가', 'head': 3.0, 'label': 'NP_SBJ', 'mod': [0.0], 'weight': 0.695618}, {'id': 2.0, 'text': '저기', 'head': 3.0, 'label': 'NP_AJT', 'mod': [], 'weight': 0.573246}, {'id': 3.0, 'text': '앉아', 'head': 4.0, 'label': 'VP', 'mod': [1.0, 2.0], 'weight': 0.750703}, {'id': 4.0, 'text': '있다', 'head': 5.0, 'label': 'VP', 'mod': [3.0], 'weight': 0.271241}, {'id': 5.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [4.0], 'weight': 0.0247723}]\n",
      "1 아이가\n",
      "37\n",
      "148241\n",
      "사투리확률 8.952507e-09\n",
      "표준어확률 0.0059404573\n",
      "[{'id': 0.0, 'text': '착한', 'head': 1.0, 'label': 'VP_MOD', 'mod': [], 'weight': 0.625791}, {'id': 1.0, 'text': '아이가', 'head': 3.0, 'label': 'NP_SBJ', 'mod': [0.0], 'weight': 0.695618}, {'id': 2.0, 'text': '저기', 'head': 3.0, 'label': 'NP_AJT', 'mod': [], 'weight': 0.573246}, {'id': 3.0, 'text': '앉아', 'head': 4.0, 'label': 'VP', 'mod': [1.0, 2.0], 'weight': 0.750703}, {'id': 4.0, 'text': '있다', 'head': 5.0, 'label': 'VP', 'mod': [3.0], 'weight': 0.271241}, {'id': 5.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [4.0], 'weight': 0.0247723}]\n",
      "4 있다\n",
      "171\n",
      "155786\n",
      "사투리확률 0.00080501946\n",
      "표준어확률 0.0050199293\n",
      "[{'id': 0.0, 'text': '착한', 'head': 1.0, 'label': 'VP_MOD', 'mod': [], 'weight': 0.625791}, {'id': 1.0, 'text': '아이가', 'head': 3.0, 'label': 'NP_SBJ', 'mod': [0.0], 'weight': 0.695618}, {'id': 2.0, 'text': '저기', 'head': 3.0, 'label': 'NP_AJT', 'mod': [], 'weight': 0.573246}, {'id': 3.0, 'text': '앉아', 'head': 4.0, 'label': 'VP', 'mod': [1.0, 2.0], 'weight': 0.750703}, {'id': 4.0, 'text': '있다', 'head': 5.0, 'label': 'VP', 'mod': [3.0], 'weight': 0.271241}, {'id': 5.0, 'text': '아이가', 'head': -1.0, 'label': 'NP_SBJ', 'mod': [4.0], 'weight': 0.0247723}]\n",
      "5 아이가\n",
      "37\n",
      "148241\n",
      "사투리확률 0.005546723\n",
      "표준어확률 1.0859945e-05\n",
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 착한 아이가 저기 앉아 있다 않아?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"착한 아이가 저기 앉아 있다 아이가?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0.0, 'text': '너처럼', 'head': 6.0, 'label': 'NP_AJT', 'mod': [], 'weight': 0.711283}, {'id': 1.0, 'text': '어린', 'head': 2.0, 'label': 'VP_MOD', 'mod': [], 'weight': 0.607093}, {'id': 2.0, 'text': '아이가', 'head': 6.0, 'label': 'NP_SBJ', 'mod': [1.0], 'weight': 0.841032}, {'id': 3.0, 'text': '무슨', 'head': 5.0, 'label': 'DP', 'mod': [], 'weight': 0.38138}, {'id': 4.0, 'text': '운전', 'head': 5.0, 'label': 'NP', 'mod': [], 'weight': 0.327299}, {'id': 5.0, 'text': '면허증을', 'head': 6.0, 'label': 'NP_OBJ', 'mod': [3.0, 4.0], 'weight': 0.687231}, {'id': 6.0, 'text': '따니', 'head': -1.0, 'label': 'VP', 'mod': [0.0, 2.0, 5.0], 'weight': 0.0258534}]\n",
      "2 아이가\n",
      "37\n",
      "148241\n",
      "사투리확률 8.952507e-09\n",
      "표준어확률 0.0059404573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 너처럼 어린 아이가 무슨 운전 면허증을 따니?'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_standard(\"너처럼 어린 아이가 무슨 운전 면허증을 따니?\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab2d543e6fcd2c9d1adcb8a11712178d53957602a005263fff7c4bba6d50274d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('name': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
